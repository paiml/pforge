<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Chapter 15: Benchmarking - pforge: EXTREME TDD for MCP Servers</title>


        <!-- Custom HTML head -->

        <meta name="description" content="Build production-ready MCP servers with EXTREME Test-Driven Development - 5-minute cycles, zero tolerance quality gates">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "coal" : "rust";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">pforge: EXTREME TDD for MCP Servers</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/paiml/pforge" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/paiml/pforge/edit/main/pforge-book/src/ch15-00-benchmarking.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="chapter-15-benchmarking-and-profiling"><a class="header" href="#chapter-15-benchmarking-and-profiling">Chapter 15: Benchmarking and Profiling</a></h1>
<p>Rigorous benchmarking is essential for maintaining pforge’s performance guarantees. This chapter covers the tools, techniques, and methodologies for measuring and tracking performance across the entire development lifecycle.</p>
<h2 id="benchmarking-philosophy"><a class="header" href="#benchmarking-philosophy">Benchmarking Philosophy</a></h2>
<p><strong>Key Principles</strong>:</p>
<ol>
<li><strong>Measure, don’t guess</strong>: Intuition about performance is often wrong</li>
<li><strong>Isolate variables</strong>: Benchmark one thing at a time</li>
<li><strong>Statistical rigor</strong>: Account for variance and outliers</li>
<li><strong>Continuous tracking</strong>: Prevent performance regressions</li>
<li><strong>Representative workloads</strong>: Test realistic scenarios</li>
</ol>
<h2 id="criterion-statistical-benchmarking"><a class="header" href="#criterion-statistical-benchmarking">Criterion: Statistical Benchmarking</a></h2>
<p>Criterion is pforge’s primary benchmarking framework, providing statistical analysis and regression detection.</p>
<h3 id="basic-benchmark-structure"><a class="header" href="#basic-benchmark-structure">Basic Benchmark Structure</a></h3>
<pre><code class="language-rust">// benches/dispatch_benchmark.rs
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use pforge_runtime::HandlerRegistry;

fn bench_handler_dispatch(c: &amp;mut Criterion) {
    let mut registry = HandlerRegistry::new();
    registry.register("test_tool", TestHandler);

    let params = serde_json::to_vec(&amp;TestInput {
        value: "test".to_string(),
    }).unwrap();

    c.bench_function("handler_dispatch", |b| {
        b.iter(|| {
            let result = registry.dispatch(
                black_box("test_tool"),
                black_box(&amp;params),
            );
            black_box(result)
        });
    });
}

criterion_group!(benches, bench_handler_dispatch);
criterion_main!(benches);</code></pre>
<p><strong>Key Functions</strong>:</p>
<ul>
<li><code>black_box()</code>: Prevents compiler from optimizing away benchmarked code</li>
<li><code>c.bench_function()</code>: Runs benchmark with automatic iteration count</li>
<li><code>b.iter()</code>: Inner benchmark loop</li>
</ul>
<h3 id="running-benchmarks"><a class="header" href="#running-benchmarks">Running Benchmarks</a></h3>
<pre><code class="language-bash"># Run all benchmarks
cargo bench

# Run specific benchmark
cargo bench --bench dispatch_benchmark

# Run with filtering
cargo bench handler

# Baseline comparison
cargo bench --save-baseline baseline-v1
# ... make changes ...
cargo bench --baseline baseline-v1

# Generate HTML report
open target/criterion/report/index.html
</code></pre>
<h3 id="benchmark-output"><a class="header" href="#benchmark-output">Benchmark Output</a></h3>
<pre><code>handler_dispatch        time:   [812.34 ns 815.92 ns 820.18 ns]
                        change: [-2.3421% -1.2103% +0.1234%] (p = 0.08 &gt; 0.05)
                        No change in performance detected.
Found 3 outliers among 100 measurements (3.00%)
  2 (2.00%) high mild
  1 (1.00%) high severe
</code></pre>
<p><strong>Reading Results</strong>:</p>
<ul>
<li><strong>time</strong>: [lower bound, estimate, upper bound] at 95% confidence</li>
<li><strong>change</strong>: Performance delta vs previous run</li>
<li><strong>outliers</strong>: Data points removed from statistical analysis</li>
<li><strong>p-value</strong>: Statistical significance (&lt; 0.05 = significant change)</li>
</ul>
<h3 id="parametric-benchmarks"><a class="header" href="#parametric-benchmarks">Parametric Benchmarks</a></h3>
<p>Compare performance across different input sizes:</p>
<pre><code class="language-rust">use criterion::BenchmarkId;

fn bench_registry_scaling(c: &amp;mut Criterion) {
    let mut group = c.benchmark_group("registry_scaling");

    for size in [10, 50, 100, 500, 1000].iter() {
        group.bench_with_input(
            BenchmarkId::from_parameter(size),
            size,
            |b, &amp;size| {
                let mut registry = HandlerRegistry::new();

                // Register `size` handlers
                for i in 0..size {
                    registry.register(
                        Box::leak(format!("tool_{}", i).into_boxed_str()),
                        TestHandler,
                    );
                }

                b.iter(|| {
                    registry.get(black_box("tool_0"))
                });
            },
        );
    }

    group.finish();
}</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>registry_scaling/10     time:   [6.8234 ns 6.9102 ns 7.0132 ns]
registry_scaling/50     time:   [7.1245 ns 7.2103 ns 7.3098 ns]
registry_scaling/100    time:   [7.3456 ns 7.4523 ns 7.5612 ns]
registry_scaling/500    time:   [8.1234 ns 8.2345 ns 8.3456 ns]
registry_scaling/1000   time:   [8.5678 ns 8.6789 ns 8.7890 ns]
</code></pre>
<p><strong>Analysis</strong>: O(1) confirmed - minimal scaling with registry size</p>
<h3 id="throughput-benchmarks"><a class="header" href="#throughput-benchmarks">Throughput Benchmarks</a></h3>
<p>Measure operations per second:</p>
<pre><code class="language-rust">use criterion::Throughput;

fn bench_json_parsing(c: &amp;mut Criterion) {
    let mut group = c.benchmark_group("json_parsing");

    for size in [100, 1024, 10240].iter() {
        let json = generate_json(*size);

        group.throughput(Throughput::Bytes(*size as u64));
        group.bench_with_input(
            BenchmarkId::from_parameter(size),
            &amp;json,
            |b, json| {
                b.iter(|| {
                    serde_json::from_slice::&lt;TestStruct&gt;(black_box(json))
                });
            },
        );
    }

    group.finish();
}</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>json_parsing/100        time:   [412.34 ns 415.92 ns 420.18 ns]
                        thrpt:  [237.95 MiB/s 240.35 MiB/s 242.51 MiB/s]

json_parsing/1024       time:   [3.1234 μs 3.2103 μs 3.3098 μs]
                        thrpt:  [309.45 MiB/s 318.92 MiB/s 327.81 MiB/s]
</code></pre>
<h3 id="custom-measurement"><a class="header" href="#custom-measurement">Custom Measurement</a></h3>
<p>For async code or complex setups:</p>
<pre><code class="language-rust">use criterion::measurement::WallTime;
use criterion::BenchmarkGroup;
use tokio::runtime::Runtime;

fn bench_async_handler(c: &amp;mut Criterion) {
    let rt = Runtime::new().unwrap();

    c.bench_function("async_handler", |b| {
        b.to_async(&amp;rt).iter(|| async {
            let handler = TestHandler;
            let input = TestInput { value: "test".to_string() };
            black_box(handler.handle(input).await)
        });
    });
}</code></pre>
<h2 id="flamegraphs-visual-cpu-profiling"><a class="header" href="#flamegraphs-visual-cpu-profiling">Flamegraphs: Visual CPU Profiling</a></h2>
<p>Flamegraphs show where CPU time is spent in your application.</p>
<h3 id="generating-flamegraphs"><a class="header" href="#generating-flamegraphs">Generating Flamegraphs</a></h3>
<pre><code class="language-bash"># Install cargo-flamegraph
cargo install flamegraph

# Generate flamegraph (Linux/macOS)
cargo flamegraph --bin pforge -- serve

# On macOS, may need sudo:
sudo cargo flamegraph --bin pforge -- serve

# Run workload (in another terminal)
# Send test requests to the server
# Press Ctrl+C to stop profiling

# View flamegraph.svg
open flamegraph.svg
</code></pre>
<h3 id="reading-flamegraphs"><a class="header" href="#reading-flamegraphs">Reading Flamegraphs</a></h3>
<p><strong>Anatomy</strong>:</p>
<ul>
<li><strong>X-axis</strong>: Alphabetical function ordering (NOT time order!)</li>
<li><strong>Y-axis</strong>: Call stack depth</li>
<li><strong>Width</strong>: Proportion of CPU time</li>
<li><strong>Color</strong>: Random (helps distinguish adjacent functions)</li>
</ul>
<p><strong>What to look for</strong>:</p>
<ol>
<li><strong>Wide boxes</strong>: Functions consuming significant CPU time</li>
<li><strong>Tall stacks</strong>: Deep call chains (potential for inlining)</li>
<li><strong>Repeated patterns</strong>: Opportunities for caching or deduplication</li>
<li><strong>Unexpected functions</strong>: Accidental expensive operations</li>
</ol>
<p><strong>Example Analysis</strong>:</p>
<pre><code>[====== serde_json::de::from_slice (45%) ======]
       [=== CalculateHandler::handle (30%) ===]
              [= registry lookup (10%) =]
                     [other (15%)]
</code></pre>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>JSON deserialization is the hottest path (45%)</li>
<li>Handler execution is second (30%)</li>
<li>Registry lookup is minimal (10%) - good!</li>
</ul>
<h3 id="differential-flamegraphs"><a class="header" href="#differential-flamegraphs">Differential Flamegraphs</a></h3>
<p>Compare before/after optimization:</p>
<pre><code class="language-bash"># Before optimization
cargo flamegraph --bin pforge -o before.svg -- serve
# ... run workload ...

# After optimization
cargo flamegraph --bin pforge -o after.svg -- serve
# ... run same workload ...

# Generate diff
diffflame before.svg after.svg &gt; diff.svg
</code></pre>
<p><strong>Diff Flamegraph Colors</strong>:</p>
<ul>
<li><strong>Red</strong>: Increased CPU time (regression)</li>
<li><strong>Blue</strong>: Decreased CPU time (improvement)</li>
<li><strong>Gray</strong>: No significant change</li>
</ul>
<h2 id="memory-profiling"><a class="header" href="#memory-profiling">Memory Profiling</a></h2>
<h3 id="valgrindmassif-for-heap-profiling"><a class="header" href="#valgrindmassif-for-heap-profiling">Valgrind/Massif for Heap Profiling</a></h3>
<pre><code class="language-bash"># Run with massif (heap profiler)
valgrind --tool=massif \
         --massif-out-file=massif.out \
         ./target/release/pforge serve

# Visualize with massif-visualizer
massif-visualizer massif.out

# Or text analysis
ms_print massif.out
</code></pre>
<p><strong>Massif Output</strong>:</p>
<pre><code>    MB
10 ^                                      #
   |                                    @:#
   |                                  @@@:#
 8 |                                @@@@:#
   |                              @@@@@@:#
   |                            @@@@@@@@:#
 6 |                          @@@@@@@@@@:#
   |                        @@@@@@@@@@@@:#
   |                      @@@@@@@@@@@@@@:#
 4 |                    @@@@@@@@@@@@@@@@:#
   |                  @@@@@@@@@@@@@@@@@@:#
   |                @@@@@@@@@@@@@@@@@@@@:#
 2 |              @@@@@@@@@@@@@@@@@@@@@@:#
   |            @@@@@@@@@@@@@@@@@@@@@@@@:#
   |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@:#
 0 +---------------------------------------&gt;ki
   0                                   1000

Number      Allocated     Frequency
-------     ---------     ---------
1           2.5 MB        45%         serde_json::de::from_slice
2           1.8 MB        32%         HandlerRegistry::register
3           0.7 MB        12%         String allocations
</code></pre>
<h3 id="dhat-rs-for-allocation-profiling"><a class="header" href="#dhat-rs-for-allocation-profiling">dhat-rs for Allocation Profiling</a></h3>
<pre><code class="language-rust">// Add to main.rs or lib.rs
#[cfg(feature = "dhat-heap")]
#[global_allocator]
static ALLOC: dhat::Alloc = dhat::Alloc;

fn main() {
    #[cfg(feature = "dhat-heap")]
    let _profiler = dhat::Profiler::new_heap();

    // ... rest of main ...
}</code></pre>
<pre><code class="language-toml"># Cargo.toml
[features]
dhat-heap = ["dhat"]

[dependencies]
dhat = { version = "0.3", optional = true }
</code></pre>
<pre><code class="language-bash"># Run with heap profiling
cargo run --release --features dhat-heap

# Generates dhat-heap.json

# View in Firefox Profiler
# Open: https://profiler.firefox.com/
# Load dhat-heap.json
</code></pre>
<p><strong>dhat Report</strong>:</p>
<ul>
<li>Total allocations</li>
<li>Total bytes allocated</li>
<li>Peak heap usage</li>
<li>Allocation hot spots</li>
<li>Allocation lifetimes</li>
</ul>
<h2 id="system-level-profiling-with-perf"><a class="header" href="#system-level-profiling-with-perf">System-Level Profiling with perf</a></h2>
<pre><code class="language-bash"># Record performance counters (Linux only)
perf record -F 99 -g --call-graph dwarf ./target/release/pforge serve

# Run workload, then Ctrl+C

# Analyze
perf report

# Generate flamegraph
perf script | stackcollapse-perf.pl | flamegraph.pl &gt; perf.svg

# Advanced: CPU cache misses
perf record -e cache-misses,cache-references ./target/release/pforge serve
perf report

# Branch prediction
perf record -e branch-misses,branches ./target/release/pforge serve
perf report
</code></pre>
<p><strong>perf stat</strong> for quick metrics:</p>
<pre><code class="language-bash">perf stat ./target/release/pforge serve
# Run workload, then Ctrl+C

# Output:
# Performance counter stats for './target/release/pforge serve':
#
#       1,234.56 msec task-clock                #    0.987 CPUs utilized
#             42      context-switches          #    0.034 K/sec
#              3      cpu-migrations            #    0.002 K/sec
#          1,234      page-faults               #    1.000 K/sec
#  4,567,890,123      cycles                    #    3.700 GHz
#  8,901,234,567      instructions              #    1.95  insn per cycle
#  1,234,567,890      branches                  # 1000.000 M/sec
#     12,345,678      branch-misses             #    1.00% of all branches
</code></pre>
<h2 id="tokio-console-async-runtime-profiling"><a class="header" href="#tokio-console-async-runtime-profiling">Tokio Console: Async Runtime Profiling</a></h2>
<p>Monitor async tasks and detect blocking operations:</p>
<pre><code class="language-toml"># Cargo.toml
[dependencies]
console-subscriber = "0.2"
tokio = { version = "1", features = ["full", "tracing"] }
</code></pre>
<pre><code class="language-rust">fn main() {
    console_subscriber::init();

    tokio::runtime::Builder::new_multi_thread()
        .enable_all()
        .build()
        .unwrap()
        .block_on(async {
            run_server().await
        });
}</code></pre>
<pre><code class="language-bash"># Terminal 1: Run server with console
cargo run --release

# Terminal 2: Start tokio-console
tokio-console

# Interact with TUI:
# - View task list
# - See task durations
# - Identify blocking tasks
# - Monitor resource usage
</code></pre>
<p><strong>Tokio Console Views</strong>:</p>
<ol>
<li>
<p><strong>Tasks View</strong>: All async tasks</p>
<pre><code>ID    STATE      TOTAL    BUSY    IDLE    POLLS
1     Running    500ms    300ms   200ms   1234
2     Idle       2.1s     100ms   2.0s    567
</code></pre>
</li>
<li>
<p><strong>Resources View</strong>: Sync primitives</p>
<pre><code>TYPE           TOTAL    OPENED   CLOSED
tcp::Stream    45       50       5
Mutex          12       12       0
</code></pre>
</li>
<li>
<p><strong>Async Operations</strong>: Await points</p>
<pre><code>LOCATION                TOTAL    AVG      MAX
handler.rs:45           1234     2.3ms    50ms
registry.rs:89          567      0.8ms    5ms
</code></pre>
</li>
</ol>
<h2 id="load-testing"><a class="header" href="#load-testing">Load Testing</a></h2>
<h3 id="wrk-for-http-load-testing"><a class="header" href="#wrk-for-http-load-testing">wrk for HTTP Load Testing</a></h3>
<pre><code class="language-bash"># Install wrk
# macOS: brew install wrk
# Linux: apt-get install wrk

# Basic load test (SSE transport)
wrk -t4 -c100 -d30s http://localhost:3000/sse

# With custom script
wrk -t4 -c100 -d30s -s loadtest.lua http://localhost:3000/sse
</code></pre>
<pre><code class="language-lua">-- loadtest.lua
request = function()
   body = [[{
     "jsonrpc": "2.0",
     "method": "tools/call",
     "params": {
       "name": "calculate",
       "arguments": {"operation": "add", "a": 5, "b": 3}
     },
     "id": 1
   }]]

   return wrk.format("POST", "/sse", nil, body)
end

response = function(status, headers, body)
   if status ~= 200 then
      print("Error: " .. status)
   end
end
</code></pre>
<p><strong>wrk Output</strong>:</p>
<pre><code>Running 30s test @ http://localhost:3000/sse
  4 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.23ms    2.45ms   50.00ms   89.12%
    Req/Sec    32.5k     3.2k    40.0k    75.00%
  3900000 requests in 30.00s, 1.50GB read
Requests/sec: 130000.00
Transfer/sec:     51.20MB
</code></pre>
<h3 id="custom-load-testing"><a class="header" href="#custom-load-testing">Custom Load Testing</a></h3>
<pre><code class="language-rust">// tests/load_test.rs
use tokio::time::{Duration, Instant};
use std::sync::Arc;
use std::sync::atomic::{AtomicU64, Ordering};

#[tokio::test(flavor = "multi_thread", worker_threads = 8)]
async fn load_test_concurrent() {
    let server = start_test_server().await;
    let success_count = Arc::new(AtomicU64::new(0));
    let error_count = Arc::new(AtomicU64::new(0));

    let start = Instant::now();
    let duration = Duration::from_secs(30);

    let mut tasks = vec![];

    // Spawn 100 concurrent clients
    for _ in 0..100 {
        let success = success_count.clone();
        let errors = error_count.clone();

        tasks.push(tokio::spawn(async move {
            while start.elapsed() &lt; duration {
                match send_request().await {
                    Ok(_) =&gt; success.fetch_add(1, Ordering::Relaxed),
                    Err(_) =&gt; errors.fetch_add(1, Ordering::Relaxed),
                };
            }
        }));
    }

    // Wait for all tasks
    for task in tasks {
        task.await.unwrap();
    }

    let elapsed = start.elapsed();
    let total_requests = success_count.load(Ordering::Relaxed);
    let total_errors = error_count.load(Ordering::Relaxed);

    println!("Load Test Results:");
    println!("  Duration: {:?}", elapsed);
    println!("  Successful requests: {}", total_requests);
    println!("  Failed requests: {}", total_errors);
    println!("  Requests/sec: {:.2}", total_requests as f64 / elapsed.as_secs_f64());

    assert!(total_errors &lt; total_requests / 100); // &lt; 1% error rate
    assert!(total_requests / elapsed.as_secs() &gt; 50000); // &gt; 50K req/s
}</code></pre>
<h2 id="continuous-benchmarking"><a class="header" href="#continuous-benchmarking">Continuous Benchmarking</a></h2>
<h3 id="github-actions-integration"><a class="header" href="#github-actions-integration">GitHub Actions Integration</a></h3>
<pre><code class="language-yaml"># .github/workflows/bench.yml
name: Benchmarks

on:
  push:
    branches: [main]
  pull_request:

jobs:
  benchmark:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: dtolnay/rust-toolchain@stable

      - name: Run benchmarks
        run: cargo bench --bench dispatch_benchmark

      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: 'criterion'
          output-file-path: target/criterion/dispatch_benchmark/base/estimates.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '110%'  # Alert if 10% slower
          comment-on-alert: true
          fail-on-alert: true
</code></pre>
<h3 id="benchmark-dashboard"><a class="header" href="#benchmark-dashboard">Benchmark Dashboard</a></h3>
<p>Track performance over time:</p>
<pre><code class="language-yaml"># Separate job for dashboard update
dashboard:
  needs: benchmark
  runs-on: ubuntu-latest
  steps:
    - uses: benchmark-action/github-action-benchmark@v1
      with:
        tool: 'criterion'
        output-file-path: target/criterion/dispatch_benchmark/base/estimates.json
        github-token: ${{ secrets.GITHUB_TOKEN}}
        gh-pages-branch: gh-pages
        benchmark-data-dir-path: 'dev/bench'
</code></pre>
<p>View at: <code>https://your-org.github.io/pforge/dev/bench/</code></p>
<h2 id="benchmark-best-practices"><a class="header" href="#benchmark-best-practices">Benchmark Best Practices</a></h2>
<h3 id="1-warm-up-phase"><a class="header" href="#1-warm-up-phase">1. Warm-Up Phase</a></h3>
<pre><code class="language-rust">fn bench_with_warmup(c: &amp;mut Criterion) {
    let mut group = c.benchmark_group("with_warmup");
    group.warm_up_time(Duration::from_secs(3)); // Warm up JIT, caches
    group.measurement_time(Duration::from_secs(10)); // Longer measurement

    group.bench_function("handler", |b| {
        b.iter(|| expensive_operation());
    });

    group.finish();
}</code></pre>
<h3 id="2-isolate-external-factors"><a class="header" href="#2-isolate-external-factors">2. Isolate External Factors</a></h3>
<pre><code class="language-rust">// Bad: Includes setup time
fn bench_bad(c: &amp;mut Criterion) {
    c.bench_function("bad", |b| {
        b.iter(|| {
            let registry = HandlerRegistry::new(); // Setup in measurement!
            registry.dispatch("tool", &amp;params)
        });
    });
}

// Good: Setup outside measurement
fn bench_good(c: &amp;mut Criterion) {
    let registry = HandlerRegistry::new(); // Setup once

    c.bench_function("good", |b| {
        b.iter(|| {
            registry.dispatch("tool", &amp;params) // Only measure dispatch
        });
    });
}</code></pre>
<h3 id="3-representative-data"><a class="header" href="#3-representative-data">3. Representative Data</a></h3>
<pre><code class="language-rust">fn bench_realistic(c: &amp;mut Criterion) {
    // Use realistic input sizes
    let small_input = generate_input(100);
    let medium_input = generate_input(1024);
    let large_input = generate_input(10240);

    c.bench_function("small", |b| b.iter(|| process(&amp;small_input)));
    c.bench_function("medium", |b| b.iter(|| process(&amp;medium_input)));
    c.bench_function("large", |b| b.iter(|| process(&amp;large_input)));
}</code></pre>
<h3 id="4-prevent-compiler-optimizations"><a class="header" href="#4-prevent-compiler-optimizations">4. Prevent Compiler Optimizations</a></h3>
<pre><code class="language-rust">use criterion::black_box;

// Bad: Compiler might optimize away the call
fn bench_bad(c: &amp;mut Criterion) {
    c.bench_function("bad", |b| {
        b.iter(|| {
            let result = expensive_function();
            // Result never used - might be optimized away!
        });
    });
}

// Good: Use black_box
fn bench_good(c: &amp;mut Criterion) {
    c.bench_function("good", |b| {
        b.iter(|| {
            let result = expensive_function();
            black_box(result) // Prevents optimization
        });
    });
}</code></pre>
<h2 id="performance-regression-testing"><a class="header" href="#performance-regression-testing">Performance Regression Testing</a></h2>
<h3 id="automated-performance-tests"><a class="header" href="#automated-performance-tests">Automated Performance Tests</a></h3>
<pre><code class="language-rust">// tests/performance_test.rs
#[test]
fn test_dispatch_latency_sla() {
    let mut registry = HandlerRegistry::new();
    registry.register("test", TestHandler);

    let params = serde_json::to_vec(&amp;TestInput::default()).unwrap();

    let start = std::time::Instant::now();
    let iterations = 10000;

    for _ in 0..iterations {
        let _ = registry.dispatch("test", &amp;params);
    }

    let elapsed = start.elapsed();
    let avg_latency = elapsed / iterations;

    // SLA: Average latency must be &lt; 1μs
    assert!(
        avg_latency &lt; Duration::from_micros(1),
        "Dispatch latency {} exceeds 1μs SLA",
        avg_latency.as_nanos()
    );
}

#[test]
fn test_memory_usage() {
    use sysinfo::{ProcessExt, System, SystemExt};

    let mut sys = System::new_all();
    let pid = sysinfo::get_current_pid().unwrap();

    sys.refresh_process(pid);
    let baseline = sys.process(pid).unwrap().memory();

    // Register 1000 handlers
    let mut registry = HandlerRegistry::new();
    for i in 0..1000 {
        registry.register(Box::leak(format!("tool_{}", i).into_boxed_str()), TestHandler);
    }

    sys.refresh_process(pid);
    let after = sys.process(pid).unwrap().memory();

    let per_handler = (after - baseline) / 1000;

    // SLA: &lt; 256 bytes per handler
    assert!(
        per_handler &lt; 256,
        "Memory per handler {} exceeds 256B SLA",
        per_handler
    );
}</code></pre>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>Effective benchmarking requires:</p>
<ol>
<li><strong>Statistical rigor</strong>: Use Criterion for reliable measurements</li>
<li><strong>Visual profiling</strong>: Flamegraphs show where time is spent</li>
<li><strong>Memory awareness</strong>: Profile allocations and heap usage</li>
<li><strong>Continuous tracking</strong>: Automate benchmarks in CI/CD</li>
<li><strong>Realistic workloads</strong>: Test production-like scenarios</li>
<li><strong>SLA enforcement</strong>: Fail tests on regression</li>
</ol>
<p><strong>Benchmarking workflow</strong>:</p>
<ol>
<li>Measure baseline with Criterion</li>
<li>Profile with flamegraphs to find hot paths</li>
<li>Optimize hot paths</li>
<li>Verify improvement with Criterion</li>
<li>Add regression test</li>
<li>Commit with confidence</li>
</ol>
<p><strong>Next chapter</strong>: Code generation internals - how pforge transforms YAML into optimized Rust.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="ch14-00-performance.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="ch16-00-codegen.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="ch14-00-performance.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="ch16-00-codegen.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>



        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="ace.js"></script>
        <script src="editor.js"></script>
        <script src="mode-rust.js"></script>
        <script src="theme-dawn.js"></script>
        <script src="theme-tomorrow_night.js"></script>

        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
